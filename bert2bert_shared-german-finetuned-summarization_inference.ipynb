{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47672055-a2c1-442d-89b0-b0a8ffad6eac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.206.0)\n",
      "Requirement already satisfied: huggingface in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.34.32)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.1)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.24.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.1)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.19.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.11.0)\n",
      "Requirement already satisfied: tblib<3,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: urllib3<1.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.18)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.66.1)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (5.9.5)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.32 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.34.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.1.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker->sagemaker) (1.6.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2023.7.22)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3.post1)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n"
     ]
    }
   ],
   "source": [
    "# Install project dependencies\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install sagemaker huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea46be34-3a4b-4488-b7ff-eae8dd78cfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::159645953966:role/service-role/SageMaker-MLOps\n",
      "sagemaker bucket: sagemaker-bert2bert\n",
      "sagemaker session region: eu-central-1\n"
     ]
    }
   ],
   "source": [
    "# INIT SAKEMAKER\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "# init session to connect to other aws ressource\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# create session bucket to store project artefacts\n",
    "sagemaker_session_bucket = \"sagemaker-bert2bert\"\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "# IAM role to allow connection to session bucket and create model deployment\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f333ba4-c41f-4073-92ce-acfbf16acab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT MODEL PIPELINE\n",
    "\n",
    "from transformers import pipeline, BertTokenizerFast\n",
    "\n",
    "# Define Model name\n",
    "model_name = \"mrm8488/bert2bert_shared-german-finetuned-summarization\"\n",
    "\n",
    "# Define Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Init download\n",
    "summarizer = pipeline(\"summarization\", model=model_name, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3005bc18-56a0-42ab-98b2-bc342f1a87c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/bitsandbytes.git\n",
      "  Cloning https://github.com/huggingface/bitsandbytes.git to /tmp/pip-req-build-if6rxmxr\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/bitsandbytes.git /tmp/pip-req-build-if6rxmxr\n",
      "Username for 'https://github.com/huggingface/bitsandbytes.git': ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install bitsandbytes\n",
    "!pip install git+https://github.com/huggingface/bitsandbytes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93493b94-2b46-40b3-8e0f-557b533f6c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2441968150.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[73], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# bitsandbytes Quantization\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "model_name = \"mrm8488/bert2bert_shared-german-finetuned-summarization\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Ersetze die linearen Schichten durch 8-Bit-quantisierte Versionen\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        # Ersetze die Schicht durch eine 8-Bit-Version\n",
    "        setattr(model, name, bnb.optim.GlobalOptimManager.get_optim(layer, optim_bits=8))\n",
    "\n",
    "# Speichere das quantisierte Modell\n",
    "model.save_pretrained('./my_quantized_bert2bert_model')\n",
    ")\n",
    "\n",
    "# Quantizated model save at model registry (s3)\n",
    "prefix = 'my-quantized-models/bert2bert'  # Dieser Prefix ist der Pfad in Ihrem Bucket.\n",
    "\n",
    "# Lokalen Pfad des Modells\n",
    "model_dir = model_save_directory\n",
    "\n",
    "# Dateien im Modellverzeichnis auflisten\n",
    "model_files = os.listdir(model_dir)\n",
    "\n",
    "# Jede Datei zum S3-Bucket hochladen\n",
    "for file in model_files:\n",
    "    local_path = os.path.join(model_dir, file)\n",
    "    s3_path = f\"s3://{bucket}/{prefix}/{file}\"\n",
    "    sagemaker_session.upload_data(path=local_path, bucket=bucket, key_prefix=f\"{prefix}/{file}\")\n",
    "    print(f\"Uploaded {local_path} to {s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed90995a-1686-42a7-9f96-7fde93e75d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zusammenfassung: Veränderungen und Innovationen sind allgegenwärtig, eine kontinuierliche und nachhaltige Weiterentwicklung der Mitarbeitenden ist von zentraler Bedeutung. Hier setzt das Praxis - Coaching an, denn es ist eine wirkungsvolle Methode, um individuelle Lern - und Entwicklungsprozesse zu fördern und zu gestalten.\n",
      "Ausführungszeit: 4.183176279067993 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# OPTIMZATION: Using BertTokenizerFast\n",
    "\n",
    "from transformers import pipeline, BertTokenizerFast\n",
    "#from transformers import pipeline, BertTokenizer\n",
    "import time\n",
    "\n",
    "# Define Model name\n",
    "model_name = \"mrm8488/bert2bert_shared-german-finetuned-summarization\"\n",
    "\n",
    "# Define Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "#tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Init download\n",
    "summarizer = pipeline(\"summarization\", model=model_name, tokenizer=tokenizer)\n",
    "\n",
    "# start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Test-Input\n",
    "text_input = (\n",
    "   \"Veränderungen und Innovationen sind allgegenwärtig, eine kontinuierliche und nachhaltige Weiterentwicklung der Mitarbeitenden ist von zentraler Bedeutung. Hier setzt das Praxis-Coaching an, denn es ist eine wirkungsvolle Methode, um individuelle Lern- und Entwicklungsprozesse zu fördern und zu gestalten. Das Praxis-Coaching Data Science unterstützt Sie dabei, den Praxistransfer in den Unternehmenskontext zu optimieren und die Rolle des Data Scientists in Ihrer Arbeitsumgebung zu etablieren. Es hilft Ihnen dabei, an die Themen des Seminars praxisnah anzuknüpfen, und ermöglicht im virtuellen 1:1-Raum mit dem:der Coach:in den Austausch für individuelle Impulse und Tipps. Der Ansatz dieses Coachings beinhaltet weder eine Wissensvermittlung noch eine Unternehmensberatung. Es geht hier in erster Linie darum, Ihre Rolle als Data Scientist gemeinsam mit dem:der Coach:in zu analysieren und Ihr Selbstvertrauen in diesem Bereich zu fördern. Das Praxis-Coaching Data Science adressiert genau dieses Dilemma: Es bringt Ihre Daten-Ideen und Ihr Wissen aus den Fachbereichen mit der Erfahrung unserer Expert:innen bei der erfolgreichen Implementierung von Datenprojekten zusammen. Egal ob eine oder zehn Stunden - buchen Sie über unser Anfrageformular ein flexibel nutzbares Kontingent mit unseren Trainer:innen. Preis pro Stunde: 250€ (297,50€ inkl MwSt).\"\n",
    "    \"Geben Sie im nächsten Schritt bei „Anfragen“ im Bemerkungsfeld an, bei welchem:welcher Trainer:in Sie gerne das Coaching durchführen wollen und wie viele Stunden Sie buchen möchten. Der:Die Trainer:in meldet sich daraufhin bei Ihnen.\"\n",
    "    \"Inhalte\"\n",
    "    \"Das Praxis-Coaching Data Science unterstützt Sie bei den folgenden Möglichkeiten:\"\n",
    "    \"Entwicklung: Etablierung Ihrer Jobrolle als Data Scientist.\"\n",
    "    \"Follow-up: Anknüpfung an die Kursinhalte und Reflexion für den maximalen Praxistransfer.\"\n",
    "    \"Entfaltung: Individuelle Impulse und Tipps für die Umsetzung von Maßnahmen in Ihrem Businesskontext.\"\n",
    "    \"Ihr Nutzen\"\n",
    "    \"Nutzen Sie dieses Praxis-Coaching für die Förderung und Gestaltung Ihres individuellen Lern- und Entwicklungsprozesses:\"\n",
    "    \"Schaffen Sie im 1:1 mit dem Experten Klarheit für Ihre neue Rolle als Data Scientist und stärken Sie dieses Mindset für sich und Ihr Team.\"\n",
    ")\n",
    "\n",
    "results = summarizer(text_input)\n",
    "\n",
    "#print summarizer results\n",
    "for result in results:\n",
    "    print(f\"Zusammenfassung: {result['summary_text']}\")\n",
    "\n",
    "# end timer\n",
    "end_time = time.time()\n",
    "\n",
    "# print time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Ausführungszeit: {execution_time} Sekunden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b01e3498-a4d9-46f9-8e90-d8115f3ab5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (60234713.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://github.com/aws/amazon-sagemaker-examples/tree/main/inference/torchserve/mme-gpu/workspace/docker\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Use DLC Container\n",
    "# https://github.com/aws/deep-learning-containers\n",
    "\n",
    "# Using own build container\n",
    "https://github.com/aws/amazon-sagemaker-examples/tree/main/inference/torchserve/mme-gpu/workspace/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819dcb12-a43b-4894-89ee-1087e7dc7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Deepspeed\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/deepspeed/GPT-J-6B_DJLServing_with_PySDK.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3ffac-8630-4518-8628-8008d16aa4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Code from Huggingface transformer libary \n",
    "!pygmentize code/inference_code.py\n",
    "\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-script-mode/blob/master/deploy-pretrained-model/BERT/Deploy_BERT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b5e88-1e50-4309-9164-1a014eda336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packaging the model\n",
    "\n",
    "import tarfile\n",
    "\n",
    "zipped_model_path = os.path.join(model_path, \"model.tar.gz\")\n",
    "\n",
    "with tarfile.open(zipped_model_path, \"w:gz\") as tar:\n",
    "    tar.add(model_path)\n",
    "    tar.add(code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0c526-2f68-46cc-9038-a9bf906c0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push model package to regitry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15149fbb-7427-42f9-bd25-c14fe652d1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy Model\n",
    "\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "endpoint_name = 'bert-base'\n",
    "\n",
    "model = PyTorchModel(entry_point='inference_code.py', \n",
    "                     model_data=zipped_model_path, \n",
    "                     role=get_execution_role(), \n",
    "                     framework_version='1.5', \n",
    "                     py_version='py3')\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.m5.xlarge', \n",
    "                         endpoint_name=endpoint_name)\n",
    "\n",
    "# Was ist der unerschied von model zu huggingface_estimator?\n",
    "predictor = huggingface_estimator.deploy(1,\"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3b332-420d-4d87-8c8c-5069585d571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba70c8-932d-44f6-82f0-c6a20bc518bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# https://docs.aws.amazon.com/de_de/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "sm = boto3.client('sagemaker-runtime')\n",
    "\n",
    "prompt = \"The best part of Amazon SageMaker is that it makes machine learning easy.\"\n",
    "\n",
    "response = sm.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                              Body=prompt.encode(encoding='UTF-8'),\n",
    "                              ContentType='text/csv')\n",
    "\n",
    "response['Body'].read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e78264-daf7-45e4-b9c8-eeb5a9dac421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serverless Inference\n",
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=1,\n",
    ")\n",
    "\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/serverless-inference/huggingface-serverless-inference/huggingface-text-classification-serverless-inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76cc6a-8829-4924-8306-1b6c1482024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics to scale based on traffic\n",
    "# https://github.com/aws/amazon-sagemaker-examples/tree/main/sagemaker-inference-recommender/auto-scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9de6b-9587-472f-b6e0-a30b047708cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF model registration\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-inference-recommender/huggingface-inference-recommender/huggingface-inference-recommender.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2605c5a-ed06-4522-aebc-f451665c5e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Clean up\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mdelete_endpoint()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7d163-1eeb-4c7b-8ca2-0a6ed759f179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
