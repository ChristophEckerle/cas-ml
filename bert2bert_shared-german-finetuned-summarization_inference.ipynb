{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "47672055-a2c1-442d-89b0-b0a8ffad6eac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.206.0)\n",
      "Requirement already satisfied: huggingface in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.34.32)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.1)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.24.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.1)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.19.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.11.0)\n",
      "Requirement already satisfied: tblib<3,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: urllib3<1.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.18)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.66.1)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (5.9.5)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.32 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.34.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.1.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker->sagemaker) (1.6.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2023.7.22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3.post1)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\tlog\n",
      "Requirement already satisfied: bitsandbytes in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scipy->bitsandbytes) (1.26.1)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install project dependencies\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install sagemaker huggingface\n",
    "!git lfs install\n",
    "#!pip install bitsandbytes\n",
    "#!pip install accelerate\n",
    "!sudo yum update -y \n",
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\n",
    "!sudo yum install git-lfs git -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea46be34-3a4b-4488-b7ff-eae8dd78cfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::159645953966:role/service-role/SageMaker-MLOps\n",
      "sagemaker bucket: sagemaker-bert2bert\n",
      "sagemaker session region: eu-central-1\n"
     ]
    }
   ],
   "source": [
    "# INIT SAKEMAKER\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "# init session to connect to other aws ressource\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# create session bucket to store project artefacts\n",
    "sagemaker_session_bucket = \"sagemaker-bert2bert\"\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "# IAM role to allow connection to session bucket and create model deployment\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04da3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: dkms-build-requires, extras_suggestions, kernel-livepatch,\n",
      "              : langpacks, priorities, update-motd, versionlock\n",
      "amzn2-core                                               | 3.6 kB     00:00     \n",
      "amzn2extra-docker                                        | 2.9 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "amzn2extra-livepatch                                     | 2.9 kB     00:00     \n",
      "amzn2extra-python3.8                                     | 2.9 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "github_git-lfs/x86_64/signature                          |  819 B     00:00     \n",
      "github_git-lfs/x86_64/signature                          |  951 B     00:02 !!! \n",
      "github_git-lfs-source/signature                          |  819 B     00:00     \n",
      "github_git-lfs-source/signature                          |  951 B     00:00 !!! \n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "centos-extras/primary_db                                   | 250 kB   00:00     \n",
      "62 packages excluded due to repository priority protections\n",
      "No packages marked for update\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, kernel-livepatch,\n",
      "              : langpacks, priorities, update-motd, versionlock\n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "62 packages excluded due to repository priority protections\n",
      "Package amazon-linux-extras-2.0.3-1.amzn2.noarch already installed and latest version\n",
      "Nothing to do\n",
      "Installing epel-release\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, kernel-livepatch,\n",
      "              : langpacks, priorities, update-motd, versionlock\n",
      "Cleaning repos: amzn2-core amzn2extra-docker amzn2extra-epel\n",
      "              : amzn2extra-kernel-5.10 amzn2extra-livepatch amzn2extra-python3.8\n",
      "              : centos-extras\n",
      "              : copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxidmap\n",
      "              : docker-ce-stable github_git-lfs github_git-lfs-source\n",
      "              : libnvidia-container neuron\n",
      "56 metadata files removed\n",
      "23 sqlite files removed\n",
      "0 metadata files removed\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, kernel-livepatch,\n",
      "              : langpacks, priorities, update-motd, versionlock\n",
      "amzn2-core                                               | 3.6 kB     00:00     \n",
      "amzn2extra-docker                                        | 2.9 kB     00:00     \n",
      "amzn2extra-epel                                          | 3.0 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "amzn2extra-livepatch                                     | 2.9 kB     00:00     \n",
      "amzn2extra-python3.8                                     | 2.9 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "github_git-lfs/x86_64/signature                          |  819 B     00:00     \n",
      "github_git-lfs/x86_64/signature                          |  951 B     00:02 !!! \n",
      "github_git-lfs-source/signature                          |  819 B     00:00     \n",
      "github_git-lfs-source/signature                          |  951 B     00:00 !!! \n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "(1/17): amzn2-core/2/x86_64/group_gz                       | 2.7 kB   00:00     \n",
      "(2/17): amzn2-core/2/x86_64/updateinfo                     | 800 kB   00:00     \n",
      "(3/17): amzn2extra-epel/2/x86_64/primary_db                | 1.8 kB   00:00     \n",
      "(4/17): amzn2extra-kernel-5.10/2/x86_64/updateinfo         |  47 kB   00:00     \n",
      "(5/17): amzn2extra-docker/2/x86_64/primary_db              | 108 kB   00:00     \n",
      "(6/17): amzn2extra-livepatch/2/x86_64/updateinfo           |  18 kB   00:00     \n",
      "(7/17): amzn2extra-docker/2/x86_64/updateinfo              |  14 kB   00:00     \n",
      "(8/17): amzn2extra-epel/2/x86_64/updateinfo                |   76 B   00:00     \n",
      "(9/17): amzn2extra-livepatch/2/x86_64/primary_db           |  54 kB   00:00     \n",
      "(10/17): amzn2extra-python3.8/2/x86_64/updateinfo          | 4.4 kB   00:00     \n",
      "(11/17): amzn2extra-python3.8/2/x86_64/primary_db          |  60 kB   00:00     \n",
      "(12/17): amzn2extra-kernel-5.10/2/x86_64/primary_db        |  23 MB   00:00     \n",
      "(13/17): copr:copr.fedorainfracloud.org:vbatts:shadow-util | 6.1 kB   00:00     \n",
      "(14/17): libnvidia-container/x86_64/primary                |  32 kB   00:00     \n",
      "(15/17): neuron/primary_db                                 | 158 kB   00:00     \n",
      "(16/17): centos-extras/primary_db                          | 250 kB   00:00     \n",
      "(17/17): amzn2-core/2/x86_64/primary_db                    |  70 MB   00:00     \n",
      "(1/2): github_git-lfs/x86_64/primary                       |  175 B   00:01     \n",
      "(2/2): github_git-lfs-source/primary                       |  175 B   00:01     \n",
      "libnvidia-container                                                     211/211\n",
      "63 packages excluded due to repository priority protections\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package epel-release.noarch 0:7-11 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package              Arch           Version      Repository               Size\n",
      "================================================================================\n",
      "Installing:\n",
      " epel-release         noarch         7-11         amzn2extra-epel          15 k\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  1 Package\n",
      "\n",
      "Total download size: 15 k\n",
      "Installed size: 24 k\n",
      "Downloading packages:\n",
      "epel-release-7-11.noarch.rpm                               |  15 kB   00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "  Installing : epel-release-7-11.noarch                                     1/1 \n",
      "  Verifying  : epel-release-7-11.noarch                                     1/1 \n",
      "\n",
      "Installed:\n",
      "  epel-release.noarch 0:7-11                                                    \n",
      "\n",
      "Complete!\n",
      "  2  httpd_modules            available  \u001b[0m  [ =1.0  =stable ]\n",
      "  3  memcached1.5             available  \u001b[0m  \\\n",
      "        [ =1.5.1  =1.5.16  =1.5.17 ]\n",
      "  9  R3.4                     available  \u001b[0m  [ =3.4.3  =stable ]\n",
      " 10  rust1                    available  \u001b[0m  \\\n",
      "        [ =1.22.1  =1.26.0  =1.26.1  =1.27.2  =1.31.0  =1.38.0\n",
      "          =stable ]\n",
      " 18  libreoffice              available  \u001b[0m  \\\n",
      "        [ =5.0.6.2_15  =5.3.6.1  =stable ]\n",
      " 19  gimp                     available  \u001b[0m  [ =2.8.22 ]\n",
      " 20 †\u001b[94mdocker=latest            enabled    \u001b[0m  \\\n",
      "        [ =17.12.1  =18.03.1  =18.06.1  =18.09.9  =stable ]\n",
      " 21  mate-desktop1.x          available  \u001b[0m  \\\n",
      "        [ =1.19.0  =1.20.0  =stable ]\n",
      " 22  GraphicsMagick1.3        available  \u001b[0m  \\\n",
      "        [ =1.3.29  =1.3.32  =1.3.34  =stable ]\n",
      " 23 †tomcat8.5                available  \u001b[0m  \\\n",
      "        [ =8.5.31  =8.5.32  =8.5.38  =8.5.40  =8.5.42  =8.5.50\n",
      "          =stable ]\n",
      " 24  \u001b[94mepel=latest              enabled    \u001b[0m  [ =7.11  =stable ]\n",
      " 25  testing                  available  \u001b[0m  [ =1.0  =stable ]\n",
      " 26  ecs                      available  \u001b[0m  [ =stable ]\n",
      " 27 †corretto8                available  \u001b[0m  \\\n",
      "        [ =1.8.0_192  =1.8.0_202  =1.8.0_212  =1.8.0_222  =1.8.0_232\n",
      "          =1.8.0_242  =stable ]\n",
      " 32  lustre2.10               available  \u001b[0m  \\\n",
      "        [ =2.10.5  =2.10.8  =stable ]\n",
      " 33 †java-openjdk11           available  \u001b[0m  [ =11  =stable ]\n",
      " 34  lynis                    available  \u001b[0m  [ =stable ]\n",
      " 36  BCC                      available  \u001b[0m  [ =0.x  =stable ]\n",
      " 37  mono                     available  \u001b[0m  [ =5.x  =stable ]\n",
      " 38  nginx1                   available  \u001b[0m  [ =stable ]\n",
      " 40  mock                     available  \u001b[0m  [ =stable ]\n",
      " 43  \u001b[94mlivepatch=latest         enabled    \u001b[0m  [ =stable ]\n",
      " 44 †\u001b[94mpython3.8=latest         enabled    \u001b[0m  [ =stable ]\n",
      " 45  haproxy2                 available  \u001b[0m  [ =stable ]\n",
      " 46  collectd                 available  \u001b[0m  [ =stable ]\n",
      " 47  aws-nitro-enclaves-cli   available  \u001b[0m  [ =stable ]\n",
      " 48  R4                       available  \u001b[0m  [ =stable ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  _  kernel-5.4               available  \u001b[0m  [ =stable ]\n",
      " 50  selinux-ng               available  \u001b[0m  [ =stable ]\n",
      " 52  tomcat9                  available  \u001b[0m  [ =stable ]\n",
      " 53  unbound1.13              available  \u001b[0m  [ =stable ]\n",
      " 54 †mariadb10.5              available  \u001b[0m  [ =stable ]\n",
      " 55  \u001b[94mkernel-5.10=latest       enabled    \u001b[0m  [ =stable ]\n",
      " 56  redis6                   available  \u001b[0m  [ =stable ]\n",
      " 57 †ruby3.0                  available  \u001b[0m  [ =stable ]\n",
      " 58 †postgresql12             available  \u001b[0m  [ =stable ]\n",
      " 59 †postgresql13             available  \u001b[0m  [ =stable ]\n",
      " 60  mock2                    available  \u001b[0m  [ =stable ]\n",
      " 61  dnsmasq2.85              available  \u001b[0m  [ =stable ]\n",
      " 62  kernel-5.15              available  \u001b[0m  [ =stable ]\n",
      " 63 †postgresql14             available  \u001b[0m  [ =stable ]\n",
      " 64  firefox                  available  \u001b[0m  [ =stable ]\n",
      " 65  lustre                   available  \u001b[0m  [ =stable ]\n",
      " 66 †php8.1                   available  \u001b[0m  [ =stable ]\n",
      " 67  awscli1                  available  \u001b[0m  [ =stable ]\n",
      " 68 †php8.2                   available  \u001b[0m  [ =stable ]\n",
      " 69  dnsmasq                  available  \u001b[0m  [ =stable ]\n",
      " 70  unbound1.17              available  \u001b[0m  [ =stable ]\n",
      " 72  collectd-python3         available  \u001b[0m  [ =stable ]\n",
      "† Note on end-of-support. Use 'info' subcommand.\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, kernel-livepatch,\n",
      "              : langpacks, priorities, update-motd, versionlock\n",
      "amzn2-core                                               | 3.6 kB     00:00     \n",
      "amzn2extra-docker                                        | 2.9 kB     00:00     \n",
      "amzn2extra-epel                                          | 3.0 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "amzn2extra-livepatch                                     | 2.9 kB     00:00     \n",
      "amzn2extra-python3.8                                     | 2.9 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "epel/x86_64/metalink                                     |  33 kB     00:00     \n",
      "epel                                                     | 4.7 kB     00:00     \n",
      "github_git-lfs/x86_64/signature                          |  819 B     00:00     \n",
      "github_git-lfs/x86_64/signature                          |  951 B     00:02 !!! \n",
      "github_git-lfs-source/signature                          |  819 B     00:00     \n",
      "github_git-lfs-source/signature                          |  951 B     00:00 !!! \n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "(1/3): epel/x86_64/group_gz                                | 100 kB   00:00     \n",
      "(2/3): epel/x86_64/updateinfo                              | 1.0 MB   00:00     \n",
      "(3/3): epel/x86_64/primary_db                              | 7.0 MB   00:00     \n",
      "289 packages excluded due to repository priority protections\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package python-lockfile.noarch 1:0.9.1-4.amzn2 will be obsoleted\n",
      "---> Package python-simplejson.x86_64 0:3.2.0-1.amzn2.0.2 will be obsoleted\n",
      "---> Package python2-lockfile.noarch 1:0.11.0-17.el7 will be obsoleting\n",
      "---> Package python2-simplejson.x86_64 0:3.11.1-1.el7 will be obsoleting\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package                  Arch         Version                 Repository  Size\n",
      "================================================================================\n",
      "Installing:\n",
      " python2-lockfile         noarch       1:0.11.0-17.el7         epel        29 k\n",
      "     replacing  python-lockfile.noarch 1:0.9.1-4.amzn2\n",
      " python2-simplejson       x86_64       3.11.1-1.el7            epel       188 k\n",
      "     replacing  python-simplejson.x86_64 3.2.0-1.amzn2.0.2\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  2 Packages\n",
      "\n",
      "Total download size: 218 k\n",
      "Downloading packages:\n",
      "warning: /var/cache/yum/x86_64/2/epel/packages/python2-lockfile-0.11.0-17.el7.noarch.rpm: Header V3 RSA/SHA256 Signature, key ID 352c64e5: NOKEY\n",
      "Public key for python2-lockfile-0.11.0-17.el7.noarch.rpm is not installed\n",
      "(1/2): python2-lockfile-0.11.0-17.el7.noarch.rpm           |  29 kB   00:00     \n",
      "(2/2): python2-simplejson-3.11.1-1.el7.x86_64.rpm          | 188 kB   00:00     \n",
      "--------------------------------------------------------------------------------\n",
      "Total                                              863 kB/s | 218 kB  00:00     \n",
      "Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\n",
      "Importing GPG key 0x352C64E5:\n",
      " Userid     : \"Fedora EPEL (7) <epel@fedoraproject.org>\"\n",
      " Fingerprint: 91e9 7d7c 4a5e 96f1 7f3e 888f 6a2f aea2 352c 64e5\n",
      " Package    : epel-release-7-11.noarch (@amzn2extra-epel)\n",
      " From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "  Installing : python2-simplejson-3.11.1-1.el7.x86_64                       1/4 \n",
      "  Installing : 1:python2-lockfile-0.11.0-17.el7.noarch                      2/4 \n",
      "  Erasing    : 1:python-lockfile-0.9.1-4.amzn2.noarch                       3/4 \n",
      "  Erasing    : python-simplejson-3.2.0-1.amzn2.0.2.x86_64                   4/4 \n",
      "  Verifying  : 1:python2-lockfile-0.11.0-17.el7.noarch                      1/4 \n",
      "  Verifying  : python2-simplejson-3.11.1-1.el7.x86_64                       2/4 \n",
      "  Verifying  : 1:python-lockfile-0.9.1-4.amzn2.noarch                       3/4 \n",
      "  Verifying  : python-simplejson-3.2.0-1.amzn2.0.2.x86_64                   4/4 \n",
      "\n",
      "Installed:\n",
      "  python2-lockfile.noarch 1:0.11.0-17.el7                                       \n",
      "  python2-simplejson.x86_64 0:3.11.1-1.el7                                      \n",
      "\n",
      "Replaced:\n",
      "  python-lockfile.noarch 1:0.9.1-4.amzn2                                        \n",
      "  python-simplejson.x86_64 0:3.2.0-1.amzn2.0.2                                  \n",
      "\n",
      "Complete!\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, kernel-livepatch,\n",
      "              : langpacks, priorities, update-motd, versionlock\n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "289 packages excluded due to repository priority protections\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package git-lfs.x86_64 0:2.10.0-2.el7 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package           Arch             Version                Repository      Size\n",
      "================================================================================\n",
      "Installing:\n",
      " git-lfs           x86_64           2.10.0-2.el7           epel           3.7 M\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  1 Package\n",
      "\n",
      "Total download size: 3.7 M\n",
      "Installed size: 13 M\n",
      "Downloading packages:\n",
      "git-lfs-2.10.0-2.el7.x86_64.rpm                            | 3.7 MB   00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "  Installing : git-lfs-2.10.0-2.el7.x86_64                                  1/1 \n",
      "  Verifying  : git-lfs-2.10.0-2.el7.x86_64                                  1/1 \n",
      "\n",
      "Installed:\n",
      "  git-lfs.x86_64 0:2.10.0-2.el7                                                 \n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "!sudo yum update -y\n",
    "!sudo yum install amazon-linux-extras\n",
    "!sudo amazon-linux-extras install epel -y\n",
    "!sudo yum update -y\n",
    "!sudo yum install git-lfs -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa5a6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert2bert_shared-german-finetuned-summarization'...\n",
      "remote: Enumerating objects: 28, done.\u001b[K\n",
      "remote: Total 28 (delta 0), reused 0 (delta 0), pack-reused 28\u001b[K\n",
      "Unpacking objects: 100% (28/28), 299.47 KiB | 1.58 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "#!git lfs install\n",
    "#!rm -rf bert2bert_shared-german-finetuned-summarization\n",
    "#!git clone https://huggingface.co/$repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6078ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't exist in S3 at /origin/bert2bert_shared-german-finetuned-summarization.tar.gz. It will be uploaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 64, 'min_length': 8, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uploaded to S3: s3://sagemaker-bert2bert/origin/bert2bert_shared-german-finetuned-summarization.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# DOWNLOAD MODEL  \n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import torch\n",
    "import boto3\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from transformers import AutoModelForSeq2SeqLM, BertTokenizerFast \n",
    "\n",
    "# Define model to download\n",
    "model_name = \"mrm8488/bert2bert_shared-german-finetuned-summarization\"\n",
    "\n",
    "# Define s3 path to store the model\n",
    "model_id = model_name.split(\"/\")[-1]\n",
    "s3_bucket = sess.default_bucket()\n",
    "s3_path = f\"s3://{s3_bucket}/origin\"\n",
    "s3_model_key = f\"/origin/{model_id}.tar.gz\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# check, if the model already exsists in the s3 bucket\n",
    "try:\n",
    "    response = s3_client.head_object(Bucket=s3_bucket, Key=s3_model_key)\n",
    "    model_exists = True\n",
    "    print(\"Model already exists in S3.\")\n",
    "except s3_client.exceptions.NoSuchKey:\n",
    "    model_exists = False\n",
    "    print(f\"Model does not exist in S3 at {s3_model_key}. It will be uploaded.\")\n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        print(f\"Model doesn't exist in S3 at {s3_model_key}. It will be uploaded.\")\n",
    "        model_exists = False\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "if not model_exists:\n",
    "    # load model and tokenizer\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "    \n",
    "    # save artefacts temporary on local disk\n",
    "    local_model_dir = f\"./{model_id}\"\n",
    "    os.makedirs(local_model_dir, exist_ok=True)\n",
    "    model.save_pretrained(local_model_dir)\n",
    "    tokenizer.save_pretrained(local_model_dir)\n",
    "    \n",
    "    # create tar.gz\n",
    "    tar_path = f\"{model_id}.tar.gz\"\n",
    "    with tarfile.open(tar_path, \"w:gz\") as tar:\n",
    "        tar.add(local_model_dir, arcname=os.path.basename(local_model_dir))\n",
    "    \n",
    "    # upload.tar.gz to s3\n",
    "    s3_tar_path = f\"{s3_path}/{tar_path}\"\n",
    "    s3_client.upload_file(tar_path, s3_bucket, f\"{model_id}/{tar_path}\")\n",
    "    print(f\"Model uploaded to S3: {s3_tar_path}\")\n",
    "    \n",
    "    # clear local\n",
    "    os.remove(tar_path)\n",
    "    os.system(f\"rm -rf {local_model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a9002f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "291efbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or `pip install bitsandbytes`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     quant_model_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quant_model_exists:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Quantisiere und speichere das Modell lokal\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mquantize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_model_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Packe das quantisierte Modell als .tar.gz\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtar -czvf 8-bit-quant-model.tar.gz -C \u001b[39m\u001b[38;5;132;01m{quant_model_dir}\u001b[39;00m\u001b[38;5;124m .\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[123], line 17\u001b[0m, in \u001b[0;36mquantize_model\u001b[0;34m(model_name, save_directory)\u001b[0m\n\u001b[1;32m     15\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Ersetze die linearen Schichten durch 8-Bit-quantisierte Versionen\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Speichere das quantisierte Modell lokal\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(save_directory)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:383\u001b[0m, in \u001b[0;36mEncoderDecoderModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFast initialization is currently not supported for EncoderDecoderModel. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to slow initialization...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    381\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fast_init\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:3032\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU found. A GPU is needed for quantization.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m-> 3032\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   3033\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3034\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `pip install bitsandbytes`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3036\u001b[0m     )\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3039\u001b[0m     \u001b[38;5;66;03m# We force the `dtype` to be float16, this is a requirement from `bitsandbytes`\u001b[39;00m\n\u001b[1;32m   3040\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   3041\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverriding torch_dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with `torch_dtype=torch.float16` due to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3042\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3043\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch_dtype=torch.float16 to remove this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3045\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or `pip install bitsandbytes`."
     ]
    }
   ],
   "source": [
    "# MODEL QUANTIZATION COMPLETE\n",
    "\n",
    "# these versions support 8-bit and 4-bit\n",
    "!pip install bitsandbytes>=0.39.0 accelerate>=0.20.0\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, BertTokenizerFast\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "\n",
    "# Funktion, um das Modell lokal zu laden und zu quantisieren\n",
    "def quantize_model(model_name, save_directory):\n",
    "    model_name = 'mrm8488/bert2bert_shared-german-finetuned-summarization'\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "    # Ersetze die linearen Schichten durch 8-Bit-quantisierte Versionen\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, load_in_8bit=True)\n",
    "    \n",
    "    # Speichere das quantisierte Modell lokal\n",
    "    model.save_pretrained(save_directory)\n",
    "    tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "# Lokalen Pfad für das quantisierte Modell definieren\n",
    "quant_model_dir = f\"8-bit-quant-{model_id}\"\n",
    "\n",
    "# Quantisierung nur durchführen, wenn das quantisierte Modell nicht bereits im S3 existiert\n",
    "try:\n",
    "    s3.head_object(Bucket=sagemaker_session_bucket, Key=f\"{quant_model_dir}/model.tar.gz\")\n",
    "    quant_model_exists = True\n",
    "except:\n",
    "    quant_model_exists = False\n",
    "\n",
    "if not quant_model_exists:\n",
    "    # Quantisiere und speichere das Modell lokal\n",
    "    quantize_model(model_id, quant_model_dir)\n",
    "\n",
    "    # Packe das quantisierte Modell als .tar.gz\n",
    "    !tar -czvf 8-bit-quant-model.tar.gz -C {quant_model_dir} .\n",
    "    \n",
    "    # Pfad im S3 für das quantisierte Modell definieren\n",
    "    s3_quant_model_path = f\"s3://{sagemaker_session_bucket}/{quant_model_dir}/model.tar.gz\"\n",
    "    \n",
    "    # Hochladen des gepackten quantisierten Modells in den S3-Bucket\n",
    "    S3Uploader.upload('8-bit-quant-model.tar.gz', s3_quant_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "04167b12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install bitsandbytes>=0.39.0 accelerate>=0.20.0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmrm8488/bert2bert_shared-german-finetuned-summarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:383\u001b[0m, in \u001b[0;36mEncoderDecoderModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFast initialization is currently not supported for EncoderDecoderModel. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to slow initialization...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    381\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fast_init\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:2996\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2993\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2994\u001b[0m         )\n\u001b[1;32m   2995\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 2996\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2997\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2998\u001b[0m         )\n\u001b[1;32m   3000\u001b[0m quantization_method_from_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quantization_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes>=0.39.0 accelerate>=0.20.0\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/bert2bert_shared-german-finetuned-summarization\", device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed90995a-1686-42a7-9f96-7fde93e75d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zusammenfassung: Veränderungen und Innovationen sind allgegenwärtig, eine kontinuierliche und nachhaltige Weiterentwicklung der Mitarbeitenden ist von zentraler Bedeutung. Hier setzt das Praxis - Coaching an, denn es ist eine wirkungsvolle Methode, um individuelle Lern - und Entwicklungsprozesse zu fördern und zu gestalten.\n",
      "Ausführungszeit: 4.239929914474487 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# OPTIMZATION: Using BertTokenizerFast\n",
    "\n",
    "from transformers import pipeline, BertTokenizer, BertTokenizerFast\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Define Model name\n",
    "model_name = \"mrm8488/bert2bert_shared-german-finetuned-summarization\"\n",
    "\n",
    "# Define Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "#tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "# Init download\n",
    "summarizer = pipeline(\"summarization\", model=model_name, tokenizer=tokenizer)\n",
    "\n",
    "# start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Test-Input\n",
    "text_input = (\n",
    "   \"Veränderungen und Innovationen sind allgegenwärtig, eine kontinuierliche und nachhaltige Weiterentwicklung der Mitarbeitenden ist von zentraler Bedeutung. Hier setzt das Praxis-Coaching an, denn es ist eine wirkungsvolle Methode, um individuelle Lern- und Entwicklungsprozesse zu fördern und zu gestalten. Das Praxis-Coaching Data Science unterstützt Sie dabei, den Praxistransfer in den Unternehmenskontext zu optimieren und die Rolle des Data Scientists in Ihrer Arbeitsumgebung zu etablieren. Es hilft Ihnen dabei, an die Themen des Seminars praxisnah anzuknüpfen, und ermöglicht im virtuellen 1:1-Raum mit dem:der Coach:in den Austausch für individuelle Impulse und Tipps. Der Ansatz dieses Coachings beinhaltet weder eine Wissensvermittlung noch eine Unternehmensberatung. Es geht hier in erster Linie darum, Ihre Rolle als Data Scientist gemeinsam mit dem:der Coach:in zu analysieren und Ihr Selbstvertrauen in diesem Bereich zu fördern. Das Praxis-Coaching Data Science adressiert genau dieses Dilemma: Es bringt Ihre Daten-Ideen und Ihr Wissen aus den Fachbereichen mit der Erfahrung unserer Expert:innen bei der erfolgreichen Implementierung von Datenprojekten zusammen. Egal ob eine oder zehn Stunden - buchen Sie über unser Anfrageformular ein flexibel nutzbares Kontingent mit unseren Trainer:innen. Preis pro Stunde: 250€ (297,50€ inkl MwSt).\"\n",
    "    \"Geben Sie im nächsten Schritt bei „Anfragen“ im Bemerkungsfeld an, bei welchem:welcher Trainer:in Sie gerne das Coaching durchführen wollen und wie viele Stunden Sie buchen möchten. Der:Die Trainer:in meldet sich daraufhin bei Ihnen.\"\n",
    "    \"Inhalte\"\n",
    "    \"Das Praxis-Coaching Data Science unterstützt Sie bei den folgenden Möglichkeiten:\"\n",
    "    \"Entwicklung: Etablierung Ihrer Jobrolle als Data Scientist.\"\n",
    "    \"Follow-up: Anknüpfung an die Kursinhalte und Reflexion für den maximalen Praxistransfer.\"\n",
    "    \"Entfaltung: Individuelle Impulse und Tipps für die Umsetzung von Maßnahmen in Ihrem Businesskontext.\"\n",
    "    \"Ihr Nutzen\"\n",
    "    \"Nutzen Sie dieses Praxis-Coaching für die Förderung und Gestaltung Ihres individuellen Lern- und Entwicklungsprozesses:\"\n",
    "    \"Schaffen Sie im 1:1 mit dem Experten Klarheit für Ihre neue Rolle als Data Scientist und stärken Sie dieses Mindset für sich und Ihr Team.\"\n",
    ")\n",
    "\n",
    "results = summarizer(text_input)\n",
    "\n",
    "#print summarizer results\n",
    "for result in results:\n",
    "    print(f\"Zusammenfassung: {result['summary_text']}\")\n",
    "\n",
    "# end timer\n",
    "end_time = time.time()\n",
    "\n",
    "# print time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Ausführungszeit: {execution_time} Sekunden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b01e3498-a4d9-46f9-8e90-d8115f3ab5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (60234713.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://github.com/aws/amazon-sagemaker-examples/tree/main/inference/torchserve/mme-gpu/workspace/docker\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Use DLC Container\n",
    "# https://github.com/aws/deep-learning-containers\n",
    "\n",
    "# Using own build container\n",
    "https://github.com/aws/amazon-sagemaker-examples/tree/main/inference/torchserve/mme-gpu/workspace/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819dcb12-a43b-4894-89ee-1087e7dc7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Deepspeed\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/deepspeed/GPT-J-6B_DJLServing_with_PySDK.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3ffac-8630-4518-8628-8008d16aa4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Code from Huggingface transformer libary \n",
    "!pygmentize code/inference_code.py\n",
    "\n",
    "\n",
    "https://github.com/aws-samples/amazon-sagemaker-script-mode/blob/master/deploy-pretrained-model/BERT/Deploy_BERT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b5e88-1e50-4309-9164-1a014eda336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packaging the model\n",
    "\n",
    "import tarfile\n",
    "\n",
    "zipped_model_path = os.path.join(model_path, \"model.tar.gz\")\n",
    "\n",
    "with tarfile.open(zipped_model_path, \"w:gz\") as tar:\n",
    "    tar.add(model_path)\n",
    "    tar.add(code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0c526-2f68-46cc-9038-a9bf906c0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push model package to regitry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15149fbb-7427-42f9-bd25-c14fe652d1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy Model\n",
    "\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "endpoint_name = 'bert-base'\n",
    "\n",
    "model = PyTorchModel(entry_point='inference_code.py', \n",
    "                     model_data=zipped_model_path, \n",
    "                     role=get_execution_role(), \n",
    "                     framework_version='1.5', \n",
    "                     py_version='py3')\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.m5.xlarge', \n",
    "                         endpoint_name=endpoint_name)\n",
    "\n",
    "# Was ist der unerschied von model zu huggingface_estimator?\n",
    "predictor = huggingface_estimator.deploy(1,\"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3b332-420d-4d87-8c8c-5069585d571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba70c8-932d-44f6-82f0-c6a20bc518bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# https://docs.aws.amazon.com/de_de/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "sm = boto3.client('sagemaker-runtime')\n",
    "\n",
    "prompt = \"The best part of Amazon SageMaker is that it makes machine learning easy.\"\n",
    "\n",
    "response = sm.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                              Body=prompt.encode(encoding='UTF-8'),\n",
    "                              ContentType='text/csv')\n",
    "\n",
    "response['Body'].read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e78264-daf7-45e4-b9c8-eeb5a9dac421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serverless Inference\n",
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=1,\n",
    ")\n",
    "\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/serverless-inference/huggingface-serverless-inference/huggingface-text-classification-serverless-inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76cc6a-8829-4924-8306-1b6c1482024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metrics to scale based on traffic\n",
    "# https://github.com/aws/amazon-sagemaker-examples/tree/main/sagemaker-inference-recommender/auto-scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9de6b-9587-472f-b6e0-a30b047708cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF model registration\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-inference-recommender/huggingface-inference-recommender/huggingface-inference-recommender.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2605c5a-ed06-4522-aebc-f451665c5e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Clean up\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mdelete_endpoint()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "llm.delete_model() # TODO\n",
    "predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7d163-1eeb-4c7b-8ca2-0a6ed759f179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
