{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad36f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo yum update -y\n",
    "!sudo yum install amazon-linux-extras\n",
    "!sudo amazon-linux-extras install epel -y\n",
    "!sudo yum update -y\n",
    "!sudo yum install git-lfs -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT SAKEMAKER\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "# init session to connect to other aws ressource\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# create session bucket to store project artefacts\n",
    "sagemaker_session_bucket = \"sagemaker-bert2bert\"\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "# IAM role to allow connection to session bucket and create model deployment\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNALOAD ORGINAL MODEL\n",
    "\n",
    "repository = \"mrm8488/bert2bert_shared-german-finetuned-summarization\"\n",
    "model_id=repository.split(\"/\")[-1]\n",
    "s3_location=f\"s3://{sess.default_bucket()}/{model_id}/model.tar.gz\"\n",
    "\n",
    "!git lfs install\n",
    "!git clone https://huggingface.co/$repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "# INIT INFERENCE SCRIPT FOR TEST\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Activate eval mode for inference\n",
    "model.eval()\n",
    "\n",
    "# Load quantized model and tokenizer\n",
    "def model_fn(model_dir):\n",
    "    model_8bit = AutoModelForSeq2SeqLM.from_pretrained(model_dir, load_in_8bit=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    return model_8bit, tokenizer\n",
    "\n",
    "def predict_fn(data, model_and_tokenizer):\n",
    "    model, tokenizer = model_and_tokenizer\n",
    "    text = data.pop(\"inputs\", data)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output_sequences = model.generate(input_ids=encoded_input['input_ids'].cuda(), **data)\n",
    "    return tokenizer.decode(output_sequences[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "# INIT INFERENCE SCRIPT FOR WEB\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sagemaker_inference import encoder, decoder\n",
    "\n",
    "# Define & load model\n",
    "MODEL_NAME = \"mrm8488/bert2bert_shared-german-finetuned-summarization\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, load_in_8bit=True)\n",
    "\n",
    "# Activate eval mode for inference\n",
    "model.eval()\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load Model for Inference:\n",
    "    \"\"\"\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    Deseralize Input-Sequences:\n",
    "    \"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        input_data = encoder.json_to_dict(request_body)\n",
    "        text = input_data['text']\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "    return text\n",
    "\n",
    "# Predict function to retrieve prediction from model\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    Generate prediction based on input sequence:\n",
    "    \"\"\"\n",
    "    # encode input via tokenizer, max_length of the BERT model is 512 inputtokens!\n",
    "    inputs = tokenizer.encode(\"summarize: \" + input_data, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # generate summarization\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # decode and return prediction\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def output_fn(prediction_output, accept):\n",
    "    \"\"\"\n",
    "    Seralize model prediction for the web:\n",
    "    \"\"\"\n",
    "    if accept == \"application/json\":\n",
    "        output = {'summary': prediction_output}\n",
    "        return encoder.encode(output, accept)\n",
    "    raise ValueError(f\"Unsupported accept type: {accept}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/requirements.txt\n",
    "\n",
    "bitsandbytes\n",
    "accelerate\n",
    "git+https://github.com/huggingface/transformers.git@main#egg=transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY MODEL to PROJECT FOR DEPLOYMENT\n",
    "!cp -r code/ $model_id/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $model_id\n",
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model.tar.gz $s3_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b930fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPLOY MODEL\n",
    "\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.13.1-transformers4.26.0-cpu-py39'\n",
    "\n",
    "# Define the Hugging Face model\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.26.0',  .\n",
    "    pytorch_version='1.13.1',  \n",
    "    py_version='py39',  \n",
    "    entry_point='inference.py', \n",
    "    role=role,  s\n",
    "    model_data=s3_location, # load from session bucket\n",
    "    image_uri=image_uri,\n",
    ")\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "\n",
    "endpoint_name = 'b2b-summarization-test'\n",
    "\n",
    "# helper to track deployment time\n",
    "start_time = time.time()\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "# helper to track deployment time\n",
    "deployment_duration = time.time() - start_time\n",
    "print(f\"Deployment completed in {deployment_duration} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c315ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODEL DEPLOYMENT\n",
    "\n",
    "data = {\n",
    "    \"inputs\": \"Veränderungen und Innovationen sind allgegenwärtig, eine kontinuierliche und nachhaltige Weiterentwicklung der Mitarbeitenden ist von zentraler Bedeutung. Hier setzt das Praxis-Coaching an, denn es ist eine wirkungsvolle Methode, um individuelle Lern- und Entwicklungsprozesse zu fördern und zu gestalten. Das Praxis-Coaching Data Science unterstützt Sie dabei, den Praxistransfer in den Unternehmenskontext zu optimieren und die Rolle des Data Scientists in Ihrer Arbeitsumgebung zu etablieren. Es hilft Ihnen dabei, an die Themen des Seminars praxisnah anzuknüpfen, und ermöglicht im virtuellen 1:1-Raum mit dem:der Coach:in den Austausch für individuelle Impulse und Tipps. Der Ansatz dieses Coachings beinhaltet weder eine Wissensvermittlung noch eine Unternehmensberatung. Es geht hier in erster Linie darum, Ihre Rolle als Data Scientist gemeinsam mit dem:der Coach:in zu analysieren und Ihr Selbstvertrauen in diesem Bereich zu fördern. Das Praxis-Coaching Data Science adressiert genau dieses Dilemma: Es bringt Ihre Daten-Ideen und Ihr Wissen aus den Fachbereichen mit der Erfahrung unserer Expert:innen bei der erfolgreichen Implementierung von Datenprojekten zusammen. Egal ob eine oder zehn Stunden - buchen Sie über unser Anfrageformular ein flexibel nutzbares Kontingent mit unseren Trainer:innen. Preis pro Stunde: 250€ (297,50€ inkl MwSt).\"\n",
    "    \"Geben Sie im nächsten Schritt bei „Anfragen“ im Bemerkungsfeld an, bei welchem:welcher Trainer:in Sie gerne das Coaching durchführen wollen und wie viele Stunden Sie buchen möchten. Der:Die Trainer:in meldet sich daraufhin bei Ihnen.\"\n",
    "    \"Inhalte\"\n",
    "    \"Das Praxis-Coaching Data Science unterstützt Sie bei den folgenden Möglichkeiten:\"\n",
    "    \"Entwicklung: Etablierung Ihrer Jobrolle als Data Scientist.\"\n",
    "    \"Follow-up: Anknüpfung an die Kursinhalte und Reflexion für den maximalen Praxistransfer.\"\n",
    "    \"Entfaltung: Individuelle Impulse und Tipps für die Umsetzung von Maßnahmen in Ihrem Businesskontext.\"\n",
    "    \"Ihr Nutzen\"\n",
    "    \"Nutzen Sie dieses Praxis-Coaching für die Förderung und Gestaltung Ihres individuellen Lern- und Entwicklungsprozesses:\"\n",
    "    \"Schaffen Sie im 1:1 mit dem Experten Klarheit für Ihre neue Rolle als Data Scientist und stärken Sie dieses Mindset für sich und Ihr Team.\",\n",
    "}\n",
    "\n",
    "response = predictor.predict(data=data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODEL HTTP-ENDPOINT DEPLOYMENT\n",
    "curl -X POST https://runtime.sagemaker.eu-central-1:159645953966:endpoint-config/b2b-summarization-test/invocations \\    \n",
    "-H 'Content-Type: application/json' \\\n",
    "-H 'Authorization: <Authentifizierung>' \\\n",
    "-d '{\"inputs\": \"Veränderungen und Innovationen sind allgegenwärtig, eine kontinuierliche und nachhaltige Weiterentwicklung der Mitarbeitenden ist von zentraler Bedeutung. Hier setzt das Praxis-Coaching an, denn es ist eine wirkungsvolle Methode, um individuelle Lern- und Entwicklungsprozesse zu fördern und zu gestalten. Das Praxis-Coaching Data Science unterstützt Sie dabei, den Praxistransfer in den Unternehmenskontext zu optimieren und die Rolle des Data Scientists in Ihrer Arbeitsumgebung zu etablieren. Es hilft Ihnen dabei, an die Themen des Seminars praxisnah anzuknüpfen, und ermöglicht im virtuellen 1:1-Raum mit dem:der Coach:in den Austausch für individuelle Impulse und Tipps. Der Ansatz dieses Coachings beinhaltet weder eine Wissensvermittlung noch eine Unternehmensberatung. Es geht hier in erster Linie darum, Ihre Rolle als Data Scientist gemeinsam mit dem:der Coach:in zu analysieren und Ihr Selbstvertrauen in diesem Bereich zu fördern. Das Praxis-Coaching Data Science adressiert genau dieses Dilemma: Es bringt Ihre Daten-Ideen und Ihr Wissen aus den Fachbereichen mit der Erfahrung unserer Expert:innen bei der erfolgreichen Implementierung von Datenprojekten zusammen. Egal ob eine oder zehn Stunden - buchen Sie über unser Anfrageformular ein flexibel nutzbares Kontingent mit unseren Trainer:innen. Preis pro Stunde: 250€ (297,50€ inkl MwSt).\"\n",
    "    \"Geben Sie im nächsten Schritt bei „Anfragen“ im Bemerkungsfeld an, bei welchem:welcher Trainer:in Sie gerne das Coaching durchführen wollen und wie viele Stunden Sie buchen möchten. Der:Die Trainer:in meldet sich daraufhin bei Ihnen.\"\n",
    "    \"Inhalte\"\n",
    "    \"Das Praxis-Coaching Data Science unterstützt Sie bei den folgenden Möglichkeiten:\"\n",
    "    \"Entwicklung: Etablierung Ihrer Jobrolle als Data Scientist.\"\n",
    "    \"Follow-up: Anknüpfung an die Kursinhalte und Reflexion für den maximalen Praxistransfer.\"\n",
    "    \"Entfaltung: Individuelle Impulse und Tipps für die Umsetzung von Maßnahmen in Ihrem Businesskontext.\"\n",
    "    \"Ihr Nutzen\"\n",
    "    \"Nutzen Sie dieses Praxis-Coaching für die Förderung und Gestaltung Ihres individuellen Lern- und Entwicklungsprozesses:\"\n",
    "    \"Schaffen Sie im 1:1 mit dem Experten Klarheit für Ihre neue Rolle als Data Scientist und stärken Sie dieses Mindset für sich und Ihr Team.\",\n",
    "    }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN UP\n",
    "predictor.delete_endpoint()\n",
    "sagemaker_session.delete_model(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
